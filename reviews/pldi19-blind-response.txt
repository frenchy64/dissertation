We thank the reviewers for their time and thorough reviews. Several
reviewers provide helpful suggestions for improvements to the
technical presentation; we will adopt these in a revised version.

## Evaluation

The most significant questions raised by the reviewers concern the
empirical evaluation of our tool. To understand this evaluation, it is
imperative to consider the _workflow_ our tool is a part of (we will
emphasize this more in the paper).

That workflow is:
1. Automatically generate an initial set of annotations.

2. Type check the program with Typed Clojure (incorrectly annotated
   programs run as normal Clojure programs)

3. Fix static typing errors by making (hopefully minor) changes.

4. Repeat steps 2&3 until the program type checks.

Of course, it would be better to automatically generate types that
work immediately, but this is impossible. Full static type inference
(as used in many prior systems) is undecidable for the Typed Clojure
type system, and similarly for other optional type systems. Dynamic
inference relies on both usually-incomplete test suites and the
ability to generalize from them. Further, most programs ported with
this process are ill-typed for at least minor reasons, even if
every annotation was generated automatically. Our workflow is thus the
only plausible approach.

Our evaluation shows that following this workflow results in a
tool-assisted recipe for porting untyped Clojure programs (sorely
needed from lack of available Typed Clojure annotations, see
"Further Challenges" [5]).

Experiment 1 demonstrates that initial annotations (Step 1) are navigable.

Experiment 2 then tests whether our porting workflow (Steps 2-4) is effective.

Experiment 3 raises confidence that initial annotations (Step 1) are meaningfully
underprecise by enforcing them with Clojure's clojure.spec (whose semantics weaken
this result for higher-order functions (L1225-1227)). It's possible
to `collect` and `infer` more specific invariants using spec (eg positive numbers),
but here spec is used as a proxy to enforce the type annotations.

The key Experiment 2 evaluates the porting workflow not in terms of
number of changes, but the *kinds* of changes needed---simple changes
are significantly preferred.

Porting 5 real-world programs consisted of only straightforward changes (Figure 13).
As noted, we omitted the changes for dj&mo (fixed in final version), but we *did*
successfully port them (see MD column).

For data.json (a JSON-processor), we infer exclusively-homogeneous
non-recursive maps and vectors whose members are sometimes overprecise 
like `all-different?` (L1053-1069). Several functions actually accepted 
keyword arguments, like `lex-partitions-H` (L1175-1192).

For mini.occ (a type checker), we infer 3 *mutually-recursive types*
for types, propositions, and expressions, with 14 total cases.  Names
are (always) derived from local information (L242-252) and entirely
depend on the squashing algorithm's effectiveness -- they end up named
`T`, `P`, and `E` because each uses a unique dispatch key `:T`, `:P`,
and `:E`.

While porting the entire 10,000+ LOC ClojureScript compiler was not
feasible, our cljs.compiler experiment shows promising results for 
using the methodology and tool with large-scale, complex Clojure programs
(with reasonable timing/memory overhead, added in final version).

Anecdotally, the tool discovers the key types expected for an
emitter (Figure 5, eg, `emit-dot` emits JavaScript for an AST representing
ClojureScript's `.` operator, and so takes an `Op`), however the porting effort
remains large, although hopefully following the form of mini.occ.


## Related Work

Several reviewers mention additional related work, as well as
requesting more detail on our relationship to existing systems such as
TypeWiz.

#### TypeWiz

Our ability to "Squash the work!" of porting real-world programs
is clear after using TypeWiz to port our tiny opening example (Figure 1).

The programmer must (L134-135) reverse engineer the overprecise annotation (Figure 2)
to ponder what it refers to and whether it should be recursive.
Extending coverage slightly to height=3 balloons the annotation size linearly (L150).
Now, the porting process is unreasonable even for a toy example:

```
  function nodes(t: {left: {left: {op: string, val: number},
                            op: string,
                            right: {op: string, val: number}},
                     op: string,
                     right: {left: {op: string, val: number},
                             op: string, 
                             right: {op: string, val: number}}}
                   |{left: {op: string, val: number},
                     op: string,
                     right: {op: string, val: number}}
                   |{op: string, val: number}) ...
```

To our knowledge, all other automatic annotation systems treat plain
data as trivially as TypeWiz (eg [4,7,10,12,15,20]). Without
recovering recursive types, there is no choice but to throw away
valuable information (eg Pytype) or suffer from enormous types (TypeWiz).

Our global squashing further distinguishes our approach (optional,
to handle excessive cross-function merging).

The DB schema inference papers are helpful, and we will discuss
them. Note that Baazizi et al recursively merge types, as we do, but
do not generate recursive types, the key novelty in our work. Bex et
al do generate recursive schemas, but have the benefit of nominal tag
names, similar to class-structured data in programming
languages. Their paper rules out schemas that would describe idiomatic
Clojure use of maps.

Review B also lists a wide variety of related work from the optional
and gradual typing literature. This work primarily focuses on static
typing and verification as well as runtime monitoring of types, which
are not closely related to our work (eg Dimoulas et al, Nguyen's work
with Van Horn et al, Furr et al, Siek & Tobin-Hochstadt). Our lazy
tracking is inspired by contract checking a la Findler & Felleisen,
and thus is related to Guo et al, which we will cite. While our
inference procedure always produces an answer, it does not insert
dynamic checks as in soft typing or quasi-static typing. We agree with
with Rastogi et al that the porting process is iterative, however their
inference optimizes programs and ours communicates suggested annotations
to programmers.

## Direct questions

Review A asks "Where did the test suites used in the evaluation come from?".
They were taken directly from the code bases as-is, emulating the experience
of a real programmer applying our tool. We agree with A that 
"coming up with good test suites is extremely labor-intensive", so the tool cannot
simply ask the user to write more tests for the tool's benefit. As we explain
in "Evaluation" above, the difficulty of the problem domain makes
many such issues unavoidable, and leaves us to make more out of the coverage
we *do* have (comparing Figure 2 & 3 shows we do exactly this).

Review A expected Experiment 3 "to be proven formally, rather than evaluated".
As explained in "Evaluation" above, creating recursive types must be an unsound process,
whose effectiveness requires other means to evaluate than soundness.

Review A is concerned about the caveat about using spec (L1225), and asks
why a spec must be inferred for a function that is already spec'ed.
We fix the misleading prose to reflect that we in fact generate *all* specs via the tool.
The *caveat* is that spec's higher-order function specs are checked generatively,
and so slightly weaken the result of Experiment 3 (that the annotations are meaningfully
underprecise). This is because generative semantics is more permissive than
standard "proxy" semantics for higher-order functions.

Review A, B are concerned that there is no detail on how to generate good names.
Name generation uses exclusively local information, hinted at in L242-252, and so is only
as good as the recursive squashing algorithms. We will make this clearer.

Review B is concerned there is no formal example for generating recursive types.

Review D is concerned that space-efficient/lazy tracking aren't evaluated.
Both are crucial optimizations for tractable time & memory performance,
especially for cljs.compiler, whose instrumented unit tests refused to complete
without them. We will be clearer in the paper, but our entire evaluation enabled *both* features.

Review D is concerned that accuracy of type annotations w.r.t. a ground truth
isn't propertly evaluated


Review D is concerned that inference of contracts is neither novel nor well evaluated.
As explained in "Evaluation" above, Experiment 3's primary purpose is evaluating
that initial *type* annotations are meaningfully underprecise. There is nothing
interesting about our generated contracts because they are simply transliterated types.
We will make this clear in the paper.

Review D is concerned that we cherry picked the "left-leaning" TypeWiz examples to make
our tool appear superior (L147-152).
We sincerely tried to show off the strengths of TypeWiz (and similar class-based systems) by showing
the recursive class-based examples in Section 1.
In the realm of class-based systems, it is so easy to infer the Node class as recursive, that is it 
difficult to consider how to *not* infer it as recursive (given sufficient tests).
This is a tough act to follow when starting from *plain data*, and yet our algorithm *outperforms*
TypeWiz via our novel squashing algorithm (Figure 3) using *identical* test coverage.

Review D asks if our approach scales to larger programs.

Review D asks if our approach is amenable to non-hash-map data structures.

