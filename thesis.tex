\documentclass[11pt]{iuthesis}
%\documentclass[11pt,final]{iuthesis}

% this is the dissertation, not the paper
\newcommand{\DISSERTATION}{}
\newcommand{\either}[2]{#1}

%\usepackage[margin=1in]{geometry}
\usepackage{savesym}
\savesymbol{r}
\savesymbol{AA}
\usepackage{esop-common}
\usepackage{infer-common}
\usepackage{symb-common}
\usepackage{quals-common}

% related to typesetting theorems, moved here for compatibility with acmart.cls
%\newcommand\@dotsep{12}

\usepackage[doublespacing]{setspace}

%\usepackage{hyperref}

\newcommand{\thesisauthor}[0]{Ambrose Bonnaire-Sergeant}
\newcommand{\thesistitle}[0]{Typed Clojure in Theory and Practice}
%\newcommand{\thesiskeywords}[0]{Kwd1, Kwd2, Kwd3}
\newcommand{\thesismonth}[0]{TODO}
\newcommand{\thesisyear}[0]{TODO}
\newcommand{\thesisdate}[0]{\today}

%% Setup for hyperref.
%\hypersetup{
%  pdftitle={\thesistitle{}},
%  pdfauthor={\thesisauthor{}},
%  colorlinks=true,
%  linkcolor=black,
%  citecolor=black,
%  urlcolor=black,
%}

%\usepackage[T1]{fontenc}

\advisor{Sam Tobin-Hochstadt}
\secondreader{Chung-chieh Shan}
\thirdreader{Ryan R. Newton}
\fourthreader{Lawrence S. Moss}
\departmentname{School}
\department{Informatics, Computing, and Engineering}
\copyrightyear{2019}
\submitdate{TODO}
\acceptdate{TODO}

% For use with iuthesis-alt.cls.
\parskip=6pt
\parindent=0pt
\normalparindent=0pt

\usepackage[top=1in,bottom=1.25in,left=1in,right=1in]{geometry}
\renewcommand{\thepart}{\Roman{part}}
\renewcommand{\thechapter}{\arabic{chapter}}

% The annoying section-only section numbering is inherited from
% amsbook, on which iuthesis-alt is based.  This is to bring back
% chapter numbers in the section headings.
\renewcommand{\thesection}{\thechapter.\arabic{section}}
\renewcommand{\thesubsection}{\thechapter.\arabic{section}.\arabic{subsection}}

% Also, put chapter numbers in figure and table numbering.
\renewcommand{\thefigure}{\arabic{chapter}.\arabic{figure}}
\renewcommand{\thetable}{\arabic{chapter}.\arabic{figure}}

% fix badly formatted toc
% https://tex.stackexchange.com/questions/22983/list-of-figures-and-list-of-tables-overlaps-figure-table-indices-with-proceeding
\makeatletter
\renewcommand*\l@figure{\@dottedtocline{1}{1.5em}{3em}}% 3em instead of 2.3em
\let\l@table\l@figure
\makeatother


\usepackage[backend=bibtex]{biblatex}
\addbibresource{bibliography.bib}

%\addtolength{\textwidth}{.5in}
%\addtolength{\textheight}{.5in}
%\setlength{\topmargin}{.25in}
%\usepackage{fontspec}
%\usepackage{hanging}
%\usepackage{xltxtra}
%\setlength{\oddsidemargin}{.75in}
%\setlength{\evensidemargin}{.25in}



\usepackage{thmtools}
%\declaretheorem[numberwithin=chapter]{example}
%\declaretheorem[numberwithin=chapter]{theorem}
%\declaretheorem[numberwithin=chapter]{lemma}
%\declaretheorem[numberwithin=chapter]{corollary}
%\declaretheorem[numberwithin=chapter]{definition}

\begin{document}

\frontmatter %turns off chapter numbering and uses roman numerals for page numbers
\title{\thesistitle{}}
\author{\thesisauthor{}}

%\begin{acknowledgements}
%\end{acknowledgements}

%\begin{dedication}
%\end{dedication}


\maketitle
\signaturepage
\copyrightpage
%\makeack
%\makededication
%\makeabstract

\input{abstract}

\singlespacing
\tableofcontents

%\listoffigures

%\listoftheorems
\doublespacing

\newpage

%turns on chapter numbering, resets page numbering and uses arabic numerals for page numbers;
\mainmatter

%\input{thesis-statement}

\chapter{Introduction}

\section{My Thesis}

\emph{Typed Clojure is a sound and practical optional type system for Clojure.}

\section{Structure of this Dissertation}

This document progresses in several parts that support my thesis statement, presented in chronological order.

Part~\ref{part:types} motivates and presents the design of Typed Clojure.
It addresses both parts of my thesis statement.

\begin{itemize}
  \item \emph{Typed Clojure is sound} I formalize Typed Clojure, including
    its characteristic features like hash-maps, multimethods, and Java interoperability,
    and prove the model type sound.
  \item \emph{Typed Clojure is practical} 
      I present an empirical study of real-world Typed Clojure usage
        in over 19,000 lines of code, showing its features correspond to actual usage patterns.
\end{itemize}

The results and industry feedback of this work inspired three distinct research directions
to help improve the experience of using Typed Clojure.

\begin{itemize}
  \item
\partref{part:autoann} presents a solution to lower the annotation burden in real-world Typed Clojure programs.
I formalize and implement a tool to automatically annotate types for top-level
user and library definitions, and empirically study the manual changes needed for the generated annotations
to pass type checking.
  \item
\partref{part:implementations} describes the design and implementation of a 
new code analyzer for Clojure, in service of enabling user-provided type rules for Clojure macros
    to help make type checking complex macro usages more robust.
\item \partref{part:symbolic-closures} motivates and describes \emph{symbolic closure types},
      a technique that enhances type checking with symbolic execution, that helps check some
      common Clojure idioms via a compatible extension of Typed Clojure's original design.
\end{itemize}

Finally, \partref{part:related-future-work} presents the related work and future directions for each part.

\part{Practical Optional Types for Clojure}
\label{part:types}

\input{esop-abstract}
\input{esop-intro}
\input{esop-overview}
\input{esop-formal-model}
\input{esop-metatheory}
\input{esop-experience}
\input{esop-conclusion}

\part{Automatic Annotations for Typed Clojure}
\label{part:autoann}

\chapter{Abstract}
\input{infer-abstract}

\input{infer-intro}
\input{infer-overview}
%\input{infer-algorithm} % old stuff
\input{infer-formalism}
\input{infer-evaluation}
\input{infer-extensions}
% infer-comparison == performance analysis vs Daikon
% this isn't in the PLDI submission so might not really fit yet
%\input{infer-comparison}
\input{infer-conclusion}

% Quals
%\part{Investigation of clojure.spec}
%\label{part:spec}
%
%\input{spec-intro}
%\input{spec-study}
%\input{spec-model}

\part{Typed Clojure Implementations}
\label{part:implementations}
\input{analyzer}

\part{%Local Type Argument Synthesis with Symbolic Closures
Symbolic Closures}
\label{part:symbolic-closures}

\input{symbolic}

\part{Related and Future Work}
\label{part:related-future-work}

\input{esop-related-work}

\input{infer-related-work}

%% NOTE: Haven't pursued the following work yet

%\paragraph{How dynamic languages are used}
%Several languages have seen similar investigations
%into their idioms as I am proposing for Clojure.
%
%A popular motivation is to discover which type system features to support
%when retrofitting a type system.
%% FIXME the is \AAkerblom but there's an error.. also in the bibliography
%Akerblom et. al~\cite{Akerblom:2014:TDF:2597073.2597103} trace dynamic features in Python programs
%via instrumentation. They measured the prevalence of dynamic features in startup versus
%user code, and recorded usage frequencies for a set of dynamic features.
%They concluded dynamism is prevalent in Python, and thus should be supported
%in a retrofitted type system for Python.
%A study along similar lines is also applicable to Clojure, in particular analysing Typed
%Clojure's support for Clojure's dynamic features.
%
%Calla{\'u} et al. \cite{Callau2013} also conducted a large-scale study of
%dynamic Smalltalk idioms to inform future language extensions tooling support.
%Notably, they further perform a qualitative analysis aiming to identify
%the reasons why Smalltalk use these features in the first place, and
%whether they can be replaced with more predictable features. They also 
%measure which kinds of projects (e.g., testing frameworks, user-level libraries, or core system libraries) 
%use particular features more frequently.
%Due to the their prevalence in the open-source Clojure ecosystem,
%Typed Clojure has mainly been tested on user-level libraries.
%We could predict Typed Clojure's applicability to other kinds of projects
%by gathering similar data on how frequently different types of Clojure libraries use
%Clojure's various features.
%
%Andreasen et. al~\cite{Andreasen2016TraceTA} developed
%\emph{trace typing} to explore the design space of JavaScript type systems. 
%Using runtime observations, they studied which control flow techniques
%are used most often in JavaScript programs, and thus, which should
%be supported by an effective type system for JavaScript.
%Typed Clojure implements occurrence typing to reason about control
%flow in Clojure which seems to work well in practice, but a similar
%quantitative analysis could reveal further insights.

%Runtime analysis \cite{Mastrangelo:2015:UYO:2814270.2814313}

%\cite{Mastrangelo:2015:UYO:2814270.2814313} 

\chapter{Related Work to Extensible Type Systems%and Interleaving Type Checking with Expansion
}

Turnstile~\cite{Chang2017TSM} type checks a program during expansion
by repurposing the Racket macro system.
Instead of the more standard approach of providing separate rules to check a macro, Turnstile
typing rules specify both the expansion and checking semantics, and so ensuring the
two are compatibile becomes automatic.
On the other hand, Typed Clojure does not have the goal of allowing users to override
how language primitives type check. Instead, our goal is to provide
a simple interface to write type rules for library functions and macros
in a style that hides the necessary bookkeeping surrounding occurrence
typing and scope management.

SugarJ~\cite{Erdweg2011SJ}
adds syntactic language extensibility to languages like Java, such as pair
syntax, embedded XML, and closures.
Desugarings are expressed as rewrite rules to plain Java.
Similarly, work on \emph{type-specific languages}~\cite{omar2014safely}
adds extensible systems for the definitions of specialized syntax literals
to existing languages.
The \emph{type} of an expression determines how it is parsed and elaborated.

% this paper has a great related works section that differentiates
% the strategies of several typed metaprogramming techniques
SoundX~\cite{Lorenzen2016STS} presents a solution to a common
dilemma in typed metaprogramming: whether to desugar before
type checking, or vice-versa.
The authors present a system where a form is type checked before 
being desugared, with a guarantee that only well-typed code is generated.
Programmers specify desugarings with a combination of typing and rewriting rules, 
which are then connected to form a valid type derivation
in a process called \emph{forwarding}.
We will explore whether we can get the same effect in Typed Clojure
without requiring the user to understand typing rules.
%For example, Scala macros~\cite{Burmako2013SML} interleave type checking and
%desugaring

Ziggurat~\cite{Fisher06staticanalysis} allows programmers to define
the static and dynamic semantics of macros separately. To demonstrate its
broad applicability, they choose Scheme-like macros that generate assembly code
for the dynamic semantics.
They advocate building towers of static analyses, so
macros can be statically checked in terms the static semantics of other macros, instead
of just their assembly code expansions which would otherwise be too difficult to check.
This idea resembles our prototypes in defining custom typing rules for functions and macros in Typed Clojure,
where the dynamic semantics are defined by runtime Clojure constructs (\texttt{defn}
and \texttt{defmacro}), and towers of static semantics are progressively specified in terms of the static
analysis of other Clojure forms.

Type Tailoring~\cite{greenmanttailoring} is an approach to provide more information
to a host type system than it might be capable of by itself.
In particular, the authors use the host platform's metaprogramming functionality
to refine the types of calls based on the program syntax alone, as well as improve
error messages by incorporating surface syntax. Their experiments are based in Typed Racket, that fully expands
syntax before checking it. Since Typed Clojure recently changed to interleave macroexpansion
and type checking, we could extend this technique to also refine calls based on the
types of their arguments (like SoundX).

Other work is relevant to our investigations of improving the user experience
of Typed Clojure. SweetT~\cite{pombrio2018inferring} automatically infers type rules
for syntactic sugar. Helium~\cite{Heeren2003STI} provides hooks into the type inference
process for domain-specific type error messages.

\chapter{Related Work to Symbolic Closures% and Combining Type Checking with Symbolic Analysis
}

\paragraph{Local Type Inference}
Symbolic closures were originally designed as an extension of Local Type Inference~\cite{PierceLTI}.
Our presentation omitted their bidirectional checking (we did not propagate type information down the syntax
tree using synthesis/checking rules)
and so was not a superset of Local Type Inference---in
particular, it does not take advantage of the relaxed optimality conditions when inferring type
arguments in checking mode.
However, adding back bidirectional checking should be possible by starting with the rules of Local
Type Inference, adding a \emph{synthesis} rule for functions that introduces a symbolic
closure, application and subtyping rules for symbolic closures, and some side conditions to restrict 
how a symbolic closure may be reasoned about (like our ``must not contain symbolic closures''
conditions scattered in various rules).
This way, a symbolic closure should only be introduced where Local Type Inference fails---when
a type of a function must be synthesized---and so seems more likely to be a superset of 
Local Type Inference.

Colored Local Type Inference~\cite{coloredlti01} extends Local Type Inference with partial
information propagation. Their type inference algorithm does not use explicit synthesis/checking
rules, instead passing ``prototypes'' \emph{P}
down the syntax tree that containing partial expected type information used for type checking.
A prototype is a type \emph{T} extended with the wildcard ``?'', denoting unknown information,
and the specific shape of a prototype denotes which type rule to use.
The rule inferring unannotated functions \ltiufun{\ltivar{}}{\ltiE{}} requires a prototype \ltiPolyFn{T}{}{P}, where
\emph{T} is the fully known expected type for {\ltivar{}}.
A symbolic closure could be introduced when checking an unannotated function with prototype
\ltiPolyFn{P}{}{P'} or ``?'' (the equivalent of Local Type Inference's ``synthesis'' rules).
In the more complicated case of \ltiPolyFn{P}{}{P'}, a symbolic reduction of 
\ltiufun{\ltivar{}}{\ltiE{}} is required to ensure it at least conforms its the prototype.
For example, inferring the type of \ltiapp{\text{map}}{\ltiufun{\ltivar{}}{\ltiE{}},[1,2,3]} with
Colored Local Type Inference (where \text{map} has type ``\ltiPolyFn{\ltiFn{\text{a}}{\text{b}},\text{List[a]}}{\text{a,b}}{\text{List[b]}}'')
checks \ltiufun{\ltivar{}}{\ltiE{}} with prototype \ltiPolyFn{\text{?}}{}{\text{?}}.
We can be optimistic and check the function 
at the largest (most specific) subtype of 
\ltiPolyFn{\ltiBot}{}{\ltiTop}
that matches \ltiPolyFn{\text{?}}{}{\text{?}}, which is \ltiPolyFn{\ltiBot}{}{\ltiTop}.
This ensures that the function at least conforms to the most optimistic interpretation of its
prototype, and then by returning a symbolic closure type instead of \ltiPolyFn{\ltiBot}{}{\ltiTop}
allows us to check more specific requirements later.
Of course, to fully check this example, it requires that we specify how type argument synthesis works with
symbolic closures, but it at least illustrates how symbolic closures relate to the rest of the system.

Spine-local type inference~\cite{DBLP:journals/corr/abs-1805-10383}
explores Local Type Inference in the context of System F (without subtyping).
They present a greedy type argument synthesis algorithm
which more aggressively propagates type information
to an application's arguments.
To check arguments, type variable instantiations are guessed
based on the expected type of the application.
For example, when checking \ltiapp{\text{id}}{\ltiufun{\ltivar{}}{\ltiE{}}}
with expected type \ltiFn{\ltiT{}}{\ltiS{}},
where \text{id} has type \ltiPolyFn{\ltitvar{}}{\ltitvar{}}{\ltitvar{}},
\ltitvar{} would be guessed to have type \ltiFn{\ltiT{}}{\ltiS{}}
and then {\ltiufun{\ltivar{}}{\ltiE{}}} would be checked at that type.
This would fail if the application was in synthesis mode.
In this specific example, symbolic closures would allow the checking
of \ltiufun{\ltivar{}}{\ltiE{}} to be delayed to when more type information
is available, in either checking or synthesis modes.
Unfortunately, it does not seem that their algorithm can check
\ltiapp{\text{map}}{\ltiufun{\ltivar{}}{\ltiE{}},[1,2,3]}
even in checking mode, and so does not seem to assist us in solving similar
problems with symbolic closures.
This case does not check because only the type of \ltiE{}
would be apparent from an expected type, not the type of \ltivar{}.

% Spine-local type inference
% - Judgement \vdash^P digs down an application to find the head
%   - happens naturally with symbolic closures
% - they use metavariables to solve direct applications
%   - can they check things like (let [x (fn [y] (inc y))] (x 1)) ?
% - they have polymorphism but not subtyping (plain System F)
%   - they speculate about extending to Fsub in related works
%   - they mention Hosoya & Pierce's "challenges" to fix hard-to-synthesize terms
% - they type check arguments left-to-right in a polymorphic application
%   - can't tell if that's different from inferring the data flow from a polytype 
%     and then checking in that order
% - their sense of "locality" is less ambitious than symbolic closures
%   - see "Type Inference Failures" section
% - good related works section for "Impredicative Polymorphism"

\paragraph{Mixing Symbolic Execution and Type Checking}
Mix~\cite{Khoo2010MTC} allows an interplay of symbolic execution~\cite{King1976SEP} with type checking
by providing syntactic regions,
with terms
\MixTregion{\ltiE{}} signaling to use type checking for {\ltiE{}},
and
\MixSregion{e} for symbolic execution.
In Mix, for example, the term
%
\[
\MixSregion{\ltilet{\text{id}}{\ltiufun{\ltivar{}}{\ltivar{}}}
                  {\MixTregion{  ...\ \MixSregion{\ltiapp{\text{id}}{3}}
                               \ ...\ \MixSregion{\ltiapp{\text{id}}{3.0}}
                               \ ... }}}
\]
%
symbolically executes \MixSregion{\ltiapp{\text{id}}{3}}
and
\MixSregion{\ltiapp{\text{id}}{3.0}}, propagating result types
\text{Int} and \text{Real} back to the typed regions, respectively.
Comparatively, symbolic closures integrates only a small amount of
symbolic execution with a type system, but in such a way that delayed symbolic computations
may pass between typed regions.
Since Mix cleanly separates symbolic execution and type checking and its formalism does not support
function types, it is difficult to compare the two approaches.
In rough terms, symbolic closures use typed regions by default and automatically adds symbolic regions
around unannotated functions.
%
\[
\MixTregion{\ltilet{\text{id}}{\MixSregion{\ltiufun{\ltivar{}}{\ltivar{}}}}
                   {  ...\ \ltiapp{\text{id}}{3}
                    \ ...\ \ltiapp{\text{id}}{3.0}
                    \ ... }}
\]
%
Typing rules are then added to introduce a symbolic closure type
and also to apply them, which involves checking the delayed body in a typed region.
%
\begin{mathpar}
\infer[]
  {}
  { \ltitjudgementNoElab{\ltiEnv{}}{\MixSregion{\ltiufun{\ltivar{}}{\ltiE{}}}}
                        {\ltiClosure{\ltiEnv{}}{\ltiufun{\ltivar{}}{\ltiE{}}}}
  }

\infer[]
  { \ltitjudgementNoElab{\ltiEnv{}}{\MixTregion{\ltiF{}}}
                        {\ltiClosure{\ltiEnvp{}}{\ltiufun{\ltivar{}}{\ltiEp{}}}}
    \\\\
    \ltitjudgementNoElab{\ltiEnv{}}{\MixTregion{\ltiE{}}}{\ltiS{}}
    \\
    \ltitjudgementNoElab{\ltiEnvConcat{\ltiEnvp{}}{\hastype{\ltivar{}}{\ltiS{}}}}
                        {\MixTregion{\ltiEp{}}}
                        {\ltiT{}}
  }
  { \ltitjudgementNoElab{\ltiEnv{}}{\MixTregion{\ltiapp{\ltiF{}}{\ltiE{}}}}{\ltiT{}}
  }
\end{mathpar}

When forced to delineate type checking from symbolic execution like this, it interesting to ask to what degree symbolic
closures even uses symbolic execution.
Our view is that (at least) symbolic closures symbolically execute the runtime-closure introduction rule.
%
\begin{mathpar}
\infer[]
  {}
  {
  \opsem {\openv{}}
         {\ltiufun{\x{}}{\e{}}}
         {\closurenosuffix{\openv{}}{\ltiufun{\x{}}{\e{}}}}
         }
\end{mathpar}
%
The symbolic closure type
{\ltiClosure{\ltiEnv{}}{\ltiufun{\ltivar{}}{\ltiE{}}}}
is then the symbolic value of the runtime closure
{\closurenosuffix{\openv{}}{\ltiufun{\x{}}{\e{}}}},
related by the following typing rule.
%
\begin{mathpar}
\infer []
{ 
  \overrightarrowcaption{
  \ltitjudgementNoElab{}{\ltiEnvLookup{\openv{}}{y}}{\ltiEnvLookup{\ltiEnv{}}{y}}
  }
  ^{y \in dom(\openv{})}
              }
{ \ltitjudgementNoElab {\ltiEnvp{}}
                       {\closurenosuffix
                        {\openv{}}
                        {\ltiufun{\ltivar{}}{\ltiE{}}}}
                       {\ltiClosure{\ltiEnv{}}{\ltiufun{\ltivar{}}{\ltiE{}}}}
          }
\end{mathpar}
%
As evidenced by the lack of symbolic regions in the above application rule,
a ``symbolic reduction'' of a symbolic closure is not particularly related
to symbolic execution---it merely kicks off some delayed type checking.
However, \ltiEnv{}, \ltiS{}, and \ltiT{} in that rule may contain symbolic closure
types, so symbolic values are being used to reason about the program.

%\begin{mathpar}
%\infer[]
%{ \opsem {\openv{}}
%         {\e{f}}
%         {\closurenosuffix {\openv{c}} {\abs {\x{}} {\t{}} {\e{b}}}}
%         \\
%  \opsem {\openv{}}
%         {\e{a}}
%         {\v{a}}
%         \\
%  \opsem {\extendopenv {\openv{c}} {\x{}} {\v{a}}}
%         {\e{b}}
%         {\v{}}
%       }
%{ \opsem {\openv{}}
%         {\appexp {\e{f}} {\e{a}}}
%         {\v{}}
%       }
%\end{mathpar}

%Symbolic closures type check an anonymous function if annotated, otherwise it is treated symbolically.
%As the authors envision, this is akin to automatically inserting
%the mode of a code region based on its context, with a Mix-like language
%becoming the intermediate language.

Mix also uses symbolic execution to enhance simple type systems with flow-sensitivity.
For example, the following Mix program uses symbolic execution 
to flow-sensitively reason about \text{int?}, a predicate that returns true only for integer values.
%
\[
\MixSregion{\ltilet{\text{f}}{\ltiufun{\ltivar{}}{(\ltiif{\ltiapp{\text{int?}}{\ltivar{}}}{\ltivar{}}{\textsf{nil}})}}
                  {\MixTregion{  ...\ \MixSregion{\ltiapp{\text{f}}{3}}
                               \ ...\ \MixSregion{\ltiapp{\text{f}}{3.0}}
                               \ ... }}}
\]
%
The symbolic regions determine
\MixSregion{\ltiapp{\text{f}}{3}} has type \text{Int} and
\MixSregion{\ltiapp{\text{f}}{3.0}} type \text{Nil} via symbolic execution.
Symbolic closures are instead designed to be compatible with flow-sensitive type systems like occurrence typing~\cite{TF10}.
Here is the analogous program using symbolic closures.
%
\[
\MixTregion{\ltilet{\text{f}}{\MixSregion{\ltiufun{\ltivar{}}{(\ltiif{\ltiapp{\text{int?}}{\ltivar{}}}{\ltivar{}}{\textsf{nil}})}}}
                  {  ...\ {\ltiapp{\text{f}}{3}}
                               \ ...\ {\ltiapp{\text{f}}{3.0}}
                               \ ... }}
\]
%
Now, let us assume occurrence typing is also used to check this program, and
that \text{int?} is typed as a predicate for integers.
The call to
{\ltiapp{\text{f}}{3}}
triggers the symbolic reduction
%
\[
\ltitjudgementNoElab{\hastype{\ltivar{}}{\text{Int}}}
                    {(\ltiif{\ltiapp{\text{int?}}{\ltivar{}}}{\ltivar{}}{\textsf{nil}})}
                    {\text{Int}}
\]
%
which has type \text{Int}, because the else-branch is unreachable, and 
similarly {\ltiapp{\text{f}}{3.0}} triggers
%
\[
\ltitjudgementNoElab{\hastype{\ltivar{}}{\text{Int}}}
                    {(\ltiif{\ltiapp{\text{int?}}{\ltivar{}}}{\ltivar{}}{\textsf{nil}})}
                    {\text{Nil}}
\]
%
which has type \text{Nil}, because the else-branch is unreachable.

% >> talk about occurrence tpying.

% Let arguments go first

% Dunfield works I need to compare to
% - Greedy Bidirectional Polymorphism
% - Sound and complete bidirectional typechecking for higher-rank polymorphism with existentials and indexed types
% - Complete and Easy Bidirectional Typechecking for Higher-Rank Polymorphism

% Other works with undecidable type checking
% - Hybrid type checking - Knowles, Flanagan

\paragraph{Intersection Type Checking}
In hindsight, the idea behind symbolic closures resembles intersection type checking,
where the same code may be checked at multiple types.
Carlier and Wells~\cite{carlier2005expansion} give an approachable explanation of ``expansion'',
a mechanism that informs an intersection type system when it should
check the same term at different types.
This is achieved by splicing typing rules (like intersection-introduction) into existing typing
derivations that are derived from the principal typings of subterms.
In contrast, symbolic closures do not assume principal types are available, and
delays the construction of typing derivation(s) for a delayed term
altogether until it is obvious how to construct it.
Then, it is matter of combining a symbolic closure's typing derivations
to recover the (intersection) type it was used at.

%In Section 3.1, they provide a motivating example for expansion, constructed to be untypable 
%with simple (non-recursive) types, and show how expansion assigns it a type.

%TODO
%With the full power of intersection type systems, a principal type expresses

%TODO how do SC relate to this statement?
% - However, computing these principal typings is as expensive as evaluation, 
%   for the simple reason that principal typings for a term in the full system
%   express all of the information in the term’s β-normal form
% - do SC perform less reductions? eg. (lambda (x) x) does not reduce, but I assume
%   the Coppo algorithm constructs a principal type for it. Then, what if it is
%   use like (lambda (z) (let ([f (lambda (x) x)]) (f (f (f z))))) ?
%   Does it still infer an intersection type for f? Obviously, SC's do nothing here.

% survey
% Expansion: the Crucial Mechanism for Type Inference with Intersection Types: A Survey and Explanation1
% https://www.sciencedirect.com/science/article/pii/S1571066105050656
% - "expansion" seems similar to inferring intersection types via symbolic closures
%   - Section 6.2 talks about type inference for rank-2 intersection types
%     - advantage is that expansion never has to introduce intersections under ->
%       - do we do this with symbolic closures?
% - "Expansion is an operation on typings that simulates the effect of splicing in typing rules
%    uses at nested positions in some derivation of that typing."
% - omega expansion looks very similar to symbolic closures types (Section 4)
%   - at least in that it embeds the term in the type to track its origin 
% - Section 5.2 talks about cost of type inference == beta reduction

% (Intersection type systems)
% Principal Types and Unification for Simple Intersection Type Systems
% https://www.sciencedirect.com/science/article/pii/S0890540185711418

\paragraph{Higher-order Control Flow Analysis}

%% (found via the expansion survey as an application of intersection types)
% http://delivery.acm.org/10.1145/260000/258951/p1-banerjee.pdf?ip=140.182.72.36&id=258951&acc=ACTIVE%20SERVICE&key=EA62C54EFA59E1BA%2EEC3C9CD27046E2ED%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&__acm__=1553786311_eb5536bb95ba54f3a2979f7a216e898e
% A Modular, Polyvariant, and Type-Based Closure Analysis, Anindya Banerjee

%TODO aka. Closure-analysis 
% http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.36.6128
% Analysis and Efficient Implementation of Functional Programs (1991), Peter Sestoft
Closure analysis~\cite{sestoft1991analysis} approximates the set of arguments which a given
function may be applied, as well as which functions a given term
may evaluate to.
Each function term is labelled 
\Sesoftlambda{\Sesoftlabel}{\ltivar{}}{\ltiE{}}, where the label {\Sesoftlabel}
abstracts over the set of all runtime closures
\closurenosuffix{\openv{}}{\Sesoftlambda{}{\ltivar{}}{\ltiE{}}}
where runtime environment {\openv{}} can choose arbitrary bindings for {\ltiE{}}'s
free term variables.
In contrast, a ``tagged'' symbolic closure term
\ltiufunelab{\ltiClosureID{}}{\ltivar{}}{\ltiE{}}
uses identifier {\ltiClosureID{}} to stand for
\closurenosuffix{\openv{}}{\ltiufun{\ltivar{}}{\ltiE{}}}
where the bindings in the runtime environment {\openv{}} are of the types
given in the type environment \ltiEnv{} where the term was encountered
by the type checker.
In an unrestricted setting of symbolic closures, the same term
may be used with different identifiers.
For example, in
%
\[
\ltilet{\text{f}}{\ltiufun{\text{x}}{\ltiufun{\text{y}}{\text{x}}}}{...{\ltiapp{\text{f}}{3}}...{\ltiapp{\text{f}}{3.0}}...}
\]
%
the first call to \text{f} tags the inner function as {\ltiufunelab{\ltiClosureID{1}}{\text{y}}{\text{x}}}
with {\ltiClosureID{1}} standing for the set of closures
whose runtime environments bind \text{x} to a value of type \text{Int},
and the second call tags it as {\ltiufunelab{\ltiClosureID{2}}{\text{y}}{\text{x}}}
with {\ltiClosureID{2}} standing for the set of closures
who similarly bind \text{x} to a value of type \text{Real}.


% https://dl.acm.org/citation.cfm?id=201001
% Closure analysis in constraint form -	Jens Palsberg


Giannini and Rocca~\cite{giannini1988characterization}
provide the following strongly-normalizing term that has no higher-order polymorphic 
type, which we write in Clojure and refer to as \GRterm.

%separate to preserve spacing
\begin{cljlisting}
(let [I (fn [a] a)
      K (fn [b] (fn [c] b))
      D (fn [d] (d d))]
  ((fn [x] (fn [y] ((y (x I))
                    (x K))))
   D))
\end{cljlisting}
%separate to preserve spacing

Palsberg~\cite{Palsberg:1995:CAC:200994.201001}
uses \GRterm to motivate program analyses
that answer basic questions like:
\begin{itemize}
  \item For every application point, which abstractions can be applied?
  \item For every abstraction, to which arguments can it be applied?
\end{itemize}
Symbolic closures answer neither of these questions.
Instead, they provide answers relevant to checking and inferring types:
\begin{itemize}
  \item Can \GRterm accept an argument of type \ltiT{}?
  \item When given an argument of type \ltiT{}, of what type are the values returned by \GRterm?
  \item Does \GRterm inhabit \ltiFn{\ltiT{}}{\ltiS{}}?
\end{itemize}
For example, type checking \GRterm with symbolic closures yields the following symbolic closure
type which we refer to as \GRclosure.

% full output
%(Closure
% {I (Closure {} (fn [a] a)),
%  K (Closure {I (Closure {} (fn [a] a))} (fn [b] (fn [c] b))),
%  D
%  (Closure
%   {I (Closure {} (fn [a] a)),
%    K (Closure {I (Closure {} (fn [a] a))} (fn [b] (fn [c] b)))}
%   (fn [d] (d d))),
%  x
%  (Closure
%   {I (Closure {} (fn [a] a)),
%    K (Closure {I (Closure {} (fn [a] a))} (fn [b] (fn [c] b)))}
%   (fn [d] (d d)))}
% (fn [y] ((y (x I)) (x K))))

%abbreviated
%(Closure
% {I (Closure {} I),
%  K (Closure {I (Closure {} I)} K),
%  D (Closure {I (Closure {} I), K (Closure {I (Closure {} I)} K)} D),
%  x (Closure {I (Closure {} I), K (Closure {I (Closure {} I)} K)} D)}
% (fn [y] ((y (x I)) (x K))))

% where Ic = (Closure {} I)
%       Kc = (Closure {I Ic} K)
%       Dc = (Closure {I Ic, K Kc} D)
%(Closure
% {I Ic,
%  K Kc,
%  D Dc,
%  x Dc}
% (fn [y] ((y (x I)) (x K))))
{
\singlespacing
\[
\begin{array}{lll}
\ltiClosure{\ltiEnv{}}{\text{\clj{(fn [y] ((y (x I)) (x K)))}}},
              \text{ where }&
{\ltiEnv{}} =  \ltiEnvConcat{\hastype{\text{\clj{I}}}{{\text{\clj{I}}}_c}}
              {\ltiEnvConcat{\hastype{\text{\clj{K}}}{{\text{\clj{K}}}_c}}
              {\ltiEnvConcat{\hastype{\text{\clj{D}}}{{\text{\clj{D}}}_c}}
              {\ltiEnvConcat{\hastype{\text{\clj{x}}}{{\text{\clj{D}}}_c}}}}}\\&
{\GRclosuretag{I}} = \ltiClosure{\ltiEnv{I}}{\text{\clj{I}}}\\&
%{\GRclosuretag{K}} = \ltiClosure{\hastype{\text{\clj{I}}}{{\text{\clj{I}}}_c}}{\text{\clj{K}}}\\&
{\GRclosuretag{K}} = \ltiClosure{\ltiEnv{k}}{\text{\clj{K}}}\\&
%{\GRclosuretag{D}} = \ltiClosure{\ltiEnvConcat{\hastype{\text{\clj{I}}}{{\text{\clj{I}}}_c}}{\hastype{\text{\clj{K}}}{{\text{\clj{K}}}_c}}}
%                                  {\text{\clj{D}}}
{\GRclosuretag{D}} = \ltiClosure{\ltiEnv{D}}{\text{\clj{D}}}\\&
\end{array}
\]
}

The term of \GRclosure is the (call-by-value) normal form of \GRterm, 
derived applying the symbolic closure of \clj{(fn [x] ...)} to  \clj{D}.
The type environment
\ltiEnv{} captures the type environment at the point the \clj{(fn [y] ...)} term
was type checked.
There, the bindings \clj{I}, \clj{K}, and \clj{D} are all symbolic closure types
{\GRclosuretag{I}},
{\GRclosuretag{K}}, and
{\GRclosuretag{D}}, respectively,
with \clj{x} also having type {\GRclosuretag{D}}
as a result of the application.
%Due to Clojure's left-to-right semantics for \clj{let} bindings, \clj{I} is also bound by
%{\ltiEnv{k}} and {\ltiEnv{D}}, and 
%\clj{K} by {\ltiEnv{D}}.

Now, we can query the symbolic closure type for \GRterm
as if it had a type, with the caveat that, without a rich enough query,
we might get a similarly benign symbolic closure type as an answer.
As explained in \secref{symbolic:section:formal-model}, two ways
to query a symbolic closure are by applying it or using subtyping.

Using our prototype of symbolic closures~\footnote{https://github.com/frenchy64/lti-model},
we can experimentally discover what shape of argument \GRterm accepts by following error messages.
After a few minutes of experimentation (and thinking),
we found that \GRterm accepts an argument of type \clj{[Any -> [Any -> Int]]}.
The following (subtyping) query leaves the return type of \GRterm to be inferred,
and tells us that \GRterm returns values of type \clj{Int} with such inputs
(\clj{(tc p e)} returns the type of \clj{e} where its expected type is the prototype \clj{p}).

\begin{cljlisting}
(tc [[Any -> [Any -> Int]] -> ?]
    GR)
;=> [[Any -> [Any -> Int]] -> Int]
\end{cljlisting}

From the type, we manually constructed a Clojure program to see what kind of \clj{Int} is being returned.
Predictably, it was the \clj{Int} we provided.

\begin{cljlisting}
(GR (fn [_] (fn [_] 42))) ;=> 42
\end{cljlisting}

Finally, we queried the \emph{type} of that program using symbolic closures,
which is \clj{Int}.

\begin{cljlisting}
(tc ?
    (GR (fn [_] (fn [_] 42))))
;=> Int
\end{cljlisting}

This illustrates the promise of symbolic closures to treat previously untypable terms
as ``black-boxes'' during type checking, especially in a setting where top-level
type information is always provided.

\paragraph{Let-polymorphism}
% \paragraph{Hindley-Milner}

%TODO
%\input{hm-comparison}

\paragraph{Directional Polymorphism}

% MLsub
% https://www.cl.cam.ac.uk/~sd601/thesis.pdf
% https://www.cl.cam.ac.uk/~sd601/papers/mlsub-preprint.pdf
%
% Polar type system (Jim)
% http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.123.8718&rep=rep1&type=pdf

% Pottier
% Simplifying Subtyping Constraints: A Theory
% http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.41.7032&rep=rep1&type=pdf
% A Framework for Type Inference with Subtyping%
% http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.55.2364&rep=rep1&type=pdf

% ML_F
% http://gallium.inria.fr/~remy/mlf/mlf-type-inference-long.pdf


%TODO
%Xie and Oliveira~\cite{xie2018let} present a type system where
%argument type information flows to the function position in applications.
%Then, defining `let` as sugar propagates enough information to avoid
%a custom rule for `let`.
%No information is propagated from functions to applications, so the benefits
%of Colored Local Type Inference are negated.

\chapter{Future work}

% Possible future work on Higher-rank types
% - see https://www.microsoft.com/en-us/research/publication/practical-type-inference-for-arbitrary-rank-types/
%   - looks like the journal version of boxy types?
%   - some notes from the paper
%     - a predicative type system only allows a polytype to be instantiated with monotypes
%     - ML_F is both impredicative and supports type inference (but costly to implement & formalize)
%       - also infers principal types
%     - higher-kinded types are orthogonal to higher-rank types, and Haskell's implementation of the former
%       happen to work well with higher-rank types (but no explanation)
%     - the concept of "syntax-directed" rules is given lots of a explanation
%     - \vdash^inst compares two _polytypes_
%     - Kfoury and Wells 1994 show that typeability of System F (with completely erased annotations) is decidable for rank 2 
%       but undecidable for rank 3>=
%     - LTI == "partial" type inference
%       - in the sense that it's not-complete (can't check all programs)
%     - nice discussion of partial type inference


\printbibliography


\newpage
\input{esop-appendix}

\end{document}
