\Dchapter{Evaluation}

We performed a qualitative evaluation of our algorithm
on several open source programs.

\paragraph{startrek-clojure}
A reimplementation of a Star Trek text adventure game.
The author created the game as a way to learn
Clojure.

\paragraph{math.combinatorics}
The core library for common combinatorics functions
for collections,
with implementations based on Knuth's Art of Computer
Programming, Volume 4.

\paragraph{fs}
A Clojure wrapper library over common Java file-system operations.

\paragraph{data.json}
A library for manipulating and outputting JSON in Clojure.

\paragraph{data.xml}
A library for manipulating and outputting XML in Clojure.

\paragraph{mini.occ}
A small model of occurrence typing by an author of the
current paper. It utilizes three mutually recursive
ad-hoc structures to represent expressions, types,
and propositions.

\paragraph{clojurescript}
ClojureScript is a Clojure variant that runs on JavaScript
virtual machines. We infer types for the compiler, the final
stage in compilation, which takes in a recursively
defined abstract syntax tree and emits JavaScript strings.

Our approach is to carry out three experiments.

\Dsection{Experiment 1: Manual inspection}

In the first experiment, we simply run our 
type inferencer on each program after executing
their tests.
We then manually inspect the resulting
types and compare them to some ideal
annotations.

We rate the quality of generated annotations
on several axes.

\paragraph{Compactness} Type annotations should be succinct,
        but without sacrificing too much accuracy.
        Are our type aliases intelligently combined
        with good choices for optional keys?

  \paragraph{Accuracy} Would executing a program with these
      type annotations cause an error?
      Have we too eagerly erased information in favor
      of compactness?

  \paragraph{Organization} Have we chosen good recursive types?
      Do they have good names?

Our first program is an implementation of a
1971 Star Trek game.
It comes with minimal tests, so to complete this experiment,
we instead played the game for 30 seconds.

\Dsection{Experiment 2: Delta needed to type check}
% TODO examples for all kinds of things
% TODO bucket how many changes are needed for each kind of thing
%      - eg. varargs, polymorphism
% TODO how many lines of code were skipped

In this experiment, we first generated types with our algorithm
by running the tests, then amended the program so that it
type checks.
We observed some frequent reasons for why changes were needed.

\paragraph{Uncalled functions}
Some functions not called at all in the unit tests.
This results in very general type annotations that need
manual changes to be useful.

For example, the startrek-clojure game has several exit
conditions, one of which is running out of time.
Since the tests do not specifically call this function,
nor play the game long enough to invoke this condition,
no useful type is inferred.

\begin{cljlisting}
(ann game-over-out-of-time AnyFunction)
\end{cljlisting}

In this case, very little effort is needed to amend this
type signature, since we generated a useful type alias
for the global configuration map.

\begin{cljlisting}
(defalias CurrentKlingonsCurrentSectorEnterpriseMap
  (HMap :mandatory
    {:current-klingons (Vec EnergySectorMap),
     :current-sector (Vec Int), 
     :enterprise EnergyIsDockedQuadrantMap,
     :quads (Vec BasesKlingonsQuadrantMap), 
     :stardate CurrentEndStartMap,
     :starting-klingons Int}
    :optional 
		{:lrs-history (Vec Str)}))
\end{cljlisting}

So we amend the signature as

\begin{cljlisting}
(ann game-over-out-of-time
  [(Atom1 CurrentKlingonsCurrentSectorEnterpriseMap) 
   -> Boolean])
\end{cljlisting}


\paragraph{Over-precision}
Returns of function types are often too restrictive, as the unit
tests may have not been complete.

There are several instances of this in math.combinatorics.
The \clj{all-different?} function
takes a collection and returns true only if the collection
contains distinct elements.
As evidenced in the generated type, the tests exercise
this functions with collections of integers, atoms,
keywords, and characters.

\begin{cljlisting}
(ann all-different?
  [(Coll (U Int (Atom1 Int) ':a ':b Character)) 
   -> Boolean])
\end{cljlisting}

In our experience, the union is very rarely a good candidate
for a Typed Clojure type signature, so a useful heuristic to improve
the generated types might be to upcast such unions to a more permissive
type, like \clj{Any}. 
In this case, we manually amend the signature as

\begin{cljlisting}
(ann all-different? [(Coll Any) :-> Boolean])
\end{cljlisting}

Another example of overprecision is the generated type
of \clj{initial-perm-numbers} a helper function
taking a \emph{frequency map}---a hash map from values
to the number of times they occur---which is the shape
of the return value of the core \clj{frequencies}
function.

The generated type shows only a frequency map where
the values are integers are exercised.

\begin{cljlisting}
(ann initial-perm-numbers
  [(Map Int Int) -> (Coll Int)])
\end{cljlisting}

A more appropriate type signature is instead

\begin{cljlisting}
(ann initial-perm-numbers
  [(Map Any Int) -> (Coll Int)])
\end{cljlisting}

In many examples of overprecision, while the generated
type might not be immediately useful to check programs,
they serve as valuable starting points and also provide
an interesting summary of test coverage.

\paragraph{Missing polymorphism}

We do not attempt to infer polymorphic function types, 
so these amendments are expected. However, it is useful
to compare the optimal types with our generated ones.

For example, the \clj{remove-nth} function in \clj{math.combinatorics}
returns a functional delete operation on its argument.
Here we can see the tests only exercise this function with
collections of integers.

\begin{cljlisting}
(ann remove-nth [(Coll Int) Int :-> (Vec Int)])
\end{cljlisting}

However, the overall shape of the function is intact,
and the manually amended type only requires a few 
keystrokes.

\begin{cljlisting}
(ann remove-nth
  (All [a] [(Coll a) Int :-> (Vec a)]))
\end{cljlisting}

Similarly, \clj{iter-perm} could be polymorphic, 
but its type is generated as

\begin{cljlisting}
(ann iter-perm [(Vec Int) :-> (U nil (Vec Int))])
\end{cljlisting}

We decided this function actually works over any number,
and bounded polymorphism was more appropriate, encoding
the fact that the elements of the output collection
are from the input collection.

\begin{cljlisting}
(ann iter-perm
  (All [a]
    [(Vec (I a Num)) -> (U nil (Vec (I a Num)))]))
\end{cljlisting}
%
%\paragraph{Missing return}
%Sometimes a function never returns, because of infinite loops
%or exceptions.

\paragraph{Missing argument counts}
Often variable argument functions are given very precise types.
Our algorithm does not apply any heuristics to approximate
variable arguments --- instead we emit types that reflect
only the arities that were called during the unit tests.

A good example of this phemonenon is the type inferred
for the \clj{plus} helper function from \clj{math.combinatorics}.
From the generated type, we can see the tests exercise this function with 2, 6,
and 7 arguments.

\begin{cljlisting}
(ann plus
  (IFn [Int Int Int Int Int Int Int :-> Int]
       [Int Int Int Int Int Int :-> Int]
       [Int Int :-> Int]))
\end{cljlisting}

Instead, \clj{plus} is actually variadic and works over any number of arguments.
It is better annotated as the following, which is easy to guess based on
both the annotated type and manually viewing the function implementation.

\begin{cljlisting}
(ann plus [Int * :-> Int])
\end{cljlisting}

A similar issue occurs with \clj{mult}.

\begin{cljlisting}
(ann mult [Int Int :-> Int]) ;; generated
(ann mult [Int * :-> Int])   ;; amended
\end{cljlisting}

A similar issue is inferring keyword arguments. Clojure implements
keyword arguments with normal variadic arguments. Notice
the generated type for \clj{lex-partitions-H},
which takes a fixed argument then some optional integer keyword
arguments. 

\begin{cljlisting}
(ann lex-partitions-H
	(IFn [Int -> (Coll (Coll (Vec Int)))]
		   [Int ':min Int ':max Int 
        -> (Coll (Coll (Coll Int)))]))
\end{cljlisting}

While the arity of the generated type is too specific,
we can conceivably use the type to help us write a better one.

\begin{cljlisting}
(ann lex-partitions-H
  [Int & :optional {:min Int :max Int}
   -> (Coll (Coll (Coll Int)))])
\end{cljlisting}

\paragraph{Weaknesses in Typed Clojure}

We encountered several known weaknesses in Typed Clojure's type system
that we had to work around.

The most invasive change needed was in startrek-clojure, which
strongly updated the global mutable configuration map on the first
time we play the game. We instead initialized the map with a dummy
value when it is first created.

\begin{verbatim}
  - get/get-in
  - apply + kw args
  - strong updates
\end{verbatim}

\paragraph{Possible errors in programs}

\begin{figure*}
\begin{tabular}{| l | l | l | l | l | l |}
  Library            & Lines of types  & Local annotations & Manual Line +/- Diff \\
  \hline
  startrek-clojure   & 133             & 3                 & +70 -41 \\
  math.combinatorics & 395             & 147               & +124 -120\\
  fs                 & 157             & 1                 & +119 -86\\
  data.json          & 168             & 9                 & +94 -125 \\
  mini.occ           & 49              & 1                 & +46 -26\\
  %data.xml           & \\
  %clojurescript & \\
\end{tabular}
\caption{Generated types}
\end{figure*}

\begin{figure*}
\begin{tabular}{| l | l | l | l | l | l | l | l |}
  Library            & Casts & Instantiation & Poly & Local ann & Shortcoming & Overprecise arg \\
  \hline
  startrek-clojure   & 5     & 0             & 0    & 2         & 13          &               \\
  math.combinatorics & 23    & 1             & 11   & 19        & 2           & 5             \\
  fs                 & 50    & 0             & 0    & 2         & 3           & 4             \\
  data.json          & & & \\
  mini.occ           & & & \\
  %data.xml           & \\
  %clojurescript & \\
\end{tabular}
\begin{tabular}{| l | l | l | l | l | l | l | l |}
  Library            & Uncalled & Nocheck & Var args & Overprecise return & kw args & added filter & Erase HVec\\
  \hline
  startrek-clojure   & & & & & &               & \\
  math.combinatorics & 0        & 9       & 3        & 2                  & 4       & 1            & 3\\
  fs                 & 4        & 11      & 2        & 9                  & 0       & 0            & 0\\
  data.json          & & & \\
  mini.occ           & & & \\
  %data.xml           & \\
  %clojurescript & \\
\end{tabular}
\caption{Number of changes needed to type check}
\end{figure*}



%\Dsection{Experiment 3: Specs pass unit tests}
%
%For our experiment, we generated specs using our algorithm and enabled
%the generated specs.
%
%
%
%\begin{figure*}
%\begin{tabular}{| l | l | l | l | l | l | l | l |}
%  Library            & Lines of spec & No. recursive specs & Instance tests & Useful map types & Passed unit tests \\
%  \hline
%  startrek-clojure   & 25            & 0                   & 10             & 0                & Yes\\
%  math.combinatorics & 601           & 0                   & 320            & 0                & Yes\\
%  fs                 & 543           & 0                   & 215            & 0                & Yes \\
%  data.json          & 401 \\
%  data.xml           & \\
%  mini.occ           & \\
%  %clojurescript & \\
%\end{tabular}
%\caption{Generated specs}
%\end{figure*}


%\Dsubsection{Experiment 3: Generating generative tests}

% We should generate the card playing specs in this guide:
% http://clojure.org/guides/spec

% # How evaluate
% ## qualitative
% Does it make sense??
% 
% 1. Don't run, gen type, manual inspection
%   - done on something small but real
%   - star trek game?
% 
% - Try different eval methods on different programs
%   - try different projects on different methods
%
% 2. Generate types, try type checking programs
%   - record what changes needed to get it to
%     type check 
%   - (on a different program than 1.) 
% 
% 3. Generate spec, insert the spec, run the test
%    with the spec on, also generate tests
%   - does spec ignore the input??
%     or just generate tests
%   - best situation:
%     - spec all passes
%     - then types check with minimal changes
%   - Q: can we use spec's tests to improve
%        types, iteratively?
%        (could throw away exceptions, throw
%         away bad input etc., different options
%         here)
% (optional)
% 4. Generate types, use gradual typing
