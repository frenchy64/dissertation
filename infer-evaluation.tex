\Dchapter{Evaluation}
\label{infer:chap:evaluation}

We performed a quantitative evaluation of our algorithm
on several open source programs.

\paragraph{startrek-clojure}
A reimplementation of a Star Trek text adventure game,
created as a way to learn Clojure.

\paragraph{math.combinatorics}
The core library for common combinatorial functions
on collections,
with implementations based on Knuth's Art of Computer
Programming, Volume 4.

\paragraph{fs}
A Clojure wrapper library over common file-system operations.

\paragraph{data.json}
A library for working with JSON.

%\paragraph{data.xml} A library for manipulating and outputting XML in Clojure.

\paragraph{mini.occ}
A model of occurrence typing by an author of the
current paper. It utilizes three mutually recursive
ad-hoc structures to represent expressions, types,
and propositions.

\paragraph{cljs.compiler}
ClojureScript (CLJS) is a Clojure variant that runs on JavaScript
virtual machines. We infer types for its compiler (written in Clojure)
which emits JavaScript from
a recursively defined map-based abstract syntax tree format.

Our approach is to carry out three experiments.

\Dsection{Experiment 1: Manual inspection}
\label{infer:sec:experiment1}

In the first experiment, we generate types for
a program and manually inspect the resulting
annotations.
We follow the criteria 
outlined in \secref{infer:sec:overview}
to judge the quality of our output, namely:
\begin{itemize}
  \item using recognizable names,
  \item favoring compact annotations, and
  \item not overspecifying types.
\end{itemize}

Since it is our largest benchmark with 448 lines
of generated type annotations,
we concentrated on manually inspecting cljs.compiler's
generated types.
We commented (\secref{infer:sec:overview})
on how successfully \figref{infer:fig:cljs}
follows our goals.
Here, we further elaborate on \figref{infer:fig:cljs}
(with line references), and contextualize them
with the elided annotations.

One remarkable success in the generated types
was the automatic inference \clj{Op} (lines \ref{infer:listing:cljs:Op}-\ref{infer:listing:cljs:Op-End})
with 14 distinct cases, and other features described in \figref{infer:fig:cljs}.
Further investigation reveals that
the compiler actually features 36 distinct AST nodes---unsurprisingly, 39 assertions was not sufficient
test coverage to discover them all.
However, because of the recognizable name and organization of
\clj{Op}, it's clear where to add the missing nodes
if no further tests are available.

A failure of cljs.compiler's
generated types was \clj{HMap49305}.
It clearly fails to be a recognizable name.
However, all is not lost:
the compactness and recognizable names of other adjacent annotations
makes it plausible for a programmer with some
knowledge of the AST representation to 
recover.
In particular 13/14 cases in \clj{Op}
have entries from \clj{:env} to \clj{HMap49305}, 
(like lines \ref{infer:listing:cljs:Op:op:const:HMap49305} and \ref{infer:listing:cljs:Op:op:do:HMap49305}),
and the only exception (line \ref{infer:listing:cljs:Op:optional:init:Op})
maps to \clj{ColumnLineContextMap}. From this information the user can
decide to combine these aliases.

Several instances of overspecification are evident,
such as the \clj{:statements} entry of a \clj{:do} AST node being inferred as an always-empty vector
(line \ref{infer:listing:cljs:Op:op:do:statements}).
In some ways, this is useful information, showing that
test coverage for \clj{:do} nodes could be improved.
To fix the annotation, we could rerun the tool with better tests.
If no such test exists, we would have to fall back
to reverse-engineering code to identify the correct
type of \clj{:statements}, which is \clj{(Vec Op)}.

Finally, 19 functions in cljs.compiler are annotated to 
take or return \clj{Op} (like lines \ref{infer:listing:cljs:emit}, \ref{infer:listing:cljs:emit-dot}).
This kind of alias reuse enables annotations
to be relatively compact (only 16 type aliases are used by the
49 functions that were exercised).

%
%We rate the quality of generated annotations
%on several axes.
%
%\paragraph{Compactness} Type annotations should be succinct,
%        but without sacrificing too much accuracy.
%        Are our type aliases intelligently combined
%        with good choices for optional keys?
%
%  \paragraph{Accuracy} Would executing a program with these
%      type annotations cause an error?
%      Have we too eagerly erased information in favor
%      of compactness?
%
%  \paragraph{Organization} Have we chosen good recursive types?
%      Do they have good names?
%
%
%\figref{infer:fig:gentype} shows our results.
%Our first program is an implementation of a
%1971 Star Trek game.
%It comes with minimal tests, so to complete this experiment,
%we instead played the game for 30 seconds.

\begin{figure*}
\begin{tabular}
{|         l   || l   | l  | l   || l  | l | l | l | l | l | l | l | l | l | l | l | l | l || l  | l  | l  | l | l |}
  Lib           & LOC  & GT  & LA & MD      & C  & I & P & L & S & O & U & N & V & R & K & F & H & LS & RS & IT & MS & UT\\ 
  \hline
  \hline
  sc            & 166  & 133 & 3  & 70/41   & 5  & 0 & 0 & 2 & 13& 1 & 5 & 1 & 1 & 2 & 0 & 0 & 0 & 25  & 0  & 10   & 0  & Y\\
  mc            & 923  & 395 & 147& 124/120 & 23 & 1 & 11& 19& 2 & 5 & 0 & 9 & 3 & 2 & 4 & 1 & 3 & 601 & 0  & 320  & 0  & Y\\
  fs            & 588  & 157 & 1  & 119/86  & 50 & 0 & 0 & 2 & 3 & 4 & 4 & 11& 2 & 9 & 0 & 0 & 0 & 543 & 0  & 215  & 0  & Y\\
  dj            & 528  & 168 & 9  & 94/125 \\
  mo            & 530  & 49  & 1  & 46/26\\
 %data.xml      &      & \\
  cc            & 1776 & 448 & 4  & N/A 
  \\
\end{tabular}
  \caption{\emph{The number of type annotations generated for each program}:
  Lib = Abbreviated library names in the order we introduce them on page \pageref{infer:chap:evaluation},
  LOC = Number of lines of code we generate types for,
  GT = Total number of lines of generated types after running our tool,
  LA = The number of local annotations generated by our tools.
  \emph{Number of manual changes needed to type check, and why they were needed}:
  MD = Lines added/removed diff from git comparing initial generated types to
       the manual amendments needed to
       type check with Typed Clojure (unless it was too difficult to port),
  C = Casts,
  I = Instantiation,
  P = Polymorphic annotation,
  L = Local annotation,
  S = Work around type system Shortcoming,
  O = Overprecise argument type,
  U = Uncalled function due to bad test coverage,
  N = Add No-check annotation to skip checking function,
  V = Add Variable arity argument type,
  R = Overprecise return type,
  K = Add Keyword argument types,
  F = Added filter annotation,
  H = Erase/upcast HVec annotation.
  \emph{Generated specs}:
  LS = Number of lines of spec generated,
  RS = No. recursive specs,
  IT = No. instance testing specs,
  MS = Useful map types,
  UT = Passed unit tests with specs enabled.
  }
  \label{infer:fig:gentype}
\end{figure*}

\Dsection{Experiment 2: Changes needed to type check}
\label{infer:sec:experiment2}
% TODO examples for all kinds of things
% TODO bucket how many changes are needed for each kind of thing
%      - eg. varargs, polymorphism
% TODO how many lines of code were skipped

In this experiment, we first generated types with our algorithm
by running the tests, then amended the program so that it
type checks.
We observed some frequent reasons for why changes were needed
(summarized in \figref{infer:fig:gentype}).

\paragraph{Uncalled functions}
A function without tests receives a broad type annotation that
must be amended.
%
For example, the startrek-clojure game has several exit
conditions, one of which is running out of time.
Since the tests do not specifically call this function,
nor play the game long enough to invoke this condition,
no useful type is inferred.
%
\begin{cljlisting}
(ann game-over-out-of-time AnyFunction)
\end{cljlisting}
%
In this case, minimal effort is needed to amend this
type signature: the appropriate type alias
already exists:
%
\begin{cljlisting}
(defalias CurrentKlingonsCurrentSectorEnterpriseMap
  (HMap :mandatory
    {:current-klingons (Vec EnergySectorMap),
     :current-sector (Vec Int), ...}
    :optional {:lrs-history (Vec Str)}))
\end{cljlisting}
%\begin{cljlisting}
%(defalias CurrentKlingonsCurrentSectorEnterpriseMap
%  (HMap :mandatory
%    {:current-klingons (Vec EnergySectorMap),
%     :current-sector (Vec Int), 
%     :enterprise EnergyIsDockedQuadrantMap,
%     :quads (Vec BasesKlingonsQuadrantMap), 
%     :stardate CurrentEndStartMap,
%     :starting-klingons Int}
%    :optional {:lrs-history (Vec Str)}))
%\end{cljlisting}
%
So we amend the signature as

\begin{cljlisting}
(ann game-over-out-of-time
  [(Atom1 CurrentKlingonsCurrentSectorEnterpriseMap) 
   -> Boolean])
\end{cljlisting}


\paragraph{Over-precision}
Function types are often too restrictive due to
insufficient unit tests.

There are several instances of this in math.combinatorics.
The \clj{all-different?} function
takes a collection and returns true only if the collection
contains distinct elements.
As evidenced in the generated type, the tests exercise
this functions with collections of integers, atoms,
keywords, and characters.

\begin{cljlisting}
(ann all-different?
  [(Coll (U Int (Atom1 Int) ':a ':b Character)) 
   -> Boolean])
\end{cljlisting}

In our experience, the union is very rarely a good candidate
for a Typed Clojure type signature, so a useful heuristic to improve
the generated types would be to upcast such unions to a more permissive
type, like \clj{Any}.
When we performed that case study, we did not yet add that heuristic
to our tool,
so in this case, we manually amend the signature as

\begin{cljlisting}
(ann all-different? [(Coll Any) -> Boolean])
\end{cljlisting}

Another example of overprecision is the generated type
of \clj{initial-perm-numbers} a helper function
taking a \emph{frequency map}---a hash map from values
to the number of times they occur---which is the shape
of the return value of the core \clj{frequencies}
function.

The generated type shows only a frequency map where
the values are integers are exercised.
%
\begin{cljlisting}
(ann initial-perm-numbers
  [(Map Int Int) -> (Coll Int)])
\end{cljlisting}
%
A more appropriate type instead takes \clj{(Map Any Int)}.
%
%\begin{cljlisting}
%(ann initial-perm-numbers
%  [(Map Any Int) -> (Coll Int)])
%\end{cljlisting}
%
In many examples of overprecision, while the generated
type might not be immediately useful to check programs,
they serve as valuable starting points and also provide
an interesting summary of test coverage.

\paragraph{Missing polymorphism}

We do not attempt to infer polymorphic function types, 
so these amendments are expected. However, it is useful
to compare the optimal types with our generated ones.

For example, the \clj{remove-nth} function in \clj{math.combinatorics}
returns a functional delete operation on its argument.
Here we can see the tests only exercise this function with
collections of integers.

\begin{cljlisting}
(ann remove-nth [(Coll Int) Int -> (Vec Int)])
\end{cljlisting}

However, the overall shape of the function is intact,
and the manually amended type only requires a few 
keystrokes.

\begin{cljlisting}
(ann remove-nth
  (All [a] [(Coll a) Int -> (Vec a)]))
\end{cljlisting}

Similarly, \clj{iter-perm} could be polymorphic, 
but its type is generated as

\begin{cljlisting}
(ann iter-perm [(Vec Int) -> (U nil (Vec Int))])
\end{cljlisting}

We decided this function actually works over any number,
and bounded polymorphism was more appropriate, encoding
the fact that the elements of the output collection
are from the input collection.

\begin{cljlisting}
(ann iter-perm
  (All [a]
    [(Vec (I a Num)) -> (U nil (Vec (I a Num)))]))
\end{cljlisting}
%
%\paragraph{Missing return}
%Sometimes a function never returns, because of infinite loops
%or exceptions.

\paragraph{Missing argument counts}
Often, variable argument functions are given very precise types.
Our algorithm does not apply any heuristics to approximate
variable arguments --- instead we emit types that reflect
only the arities that were called during the unit tests.

A good example of this phemonenon is the type inferred
for the \clj{plus} helper function from \clj{math.combinatorics}.
From the generated type, we can see the tests exercise this function with 2, 6,
and 7 arguments.

\begin{cljlisting}
(ann plus (IFn [Int Int Int Int Int Int Int -> Int]
               [Int Int Int Int Int Int -> Int]
               [Int Int -> Int]))
\end{cljlisting}

Instead, \clj{plus} is actually variadic and works over any number of arguments.
It is better annotated as the following, which is easy to guess based on
both the annotated type and manually viewing the function implementation.

\begin{cljlisting}
(ann plus [Int * -> Int])
\end{cljlisting}

A similar issue occurs with \clj{mult}.

\begin{cljlisting}
(ann mult [Int Int -> Int]) ;; generated
(ann mult [Int * -> Int])   ;; amended
\end{cljlisting}

A similar issue is inferring keyword arguments. Clojure implements
keyword arguments with normal variadic arguments. Notice
the generated type for \clj{lex-partitions-H},
which takes a fixed argument, followed by some optional integer keyword
arguments. 

\begin{cljlisting}
(ann lex-partitions-H
  (IFn [Int -> (Coll (Coll (Vec Int)))]
       [Int ':min Int ':max Int 
        -> (Coll (Coll (Coll Int)))]))
\end{cljlisting}

While the arity of the generated type is too specific,
we can conceivably use the type to help us write a better one.

\begin{cljlisting}
(ann lex-partitions-H
  [Int & :optional {:min Int :max Int}
   -> (Coll (Coll (Coll Int)))])
\end{cljlisting}

\paragraph{Weaknesses in Typed Clojure}

We encountered several known weaknesses in Typed Clojure's type system
that we worked around.
%
The most invasive change needed was in startrek-clojure, which
strongly updated the global mutable configuration map on initial
play . We instead initialized the map with a dummy
value when it is first created.

cljs.compiler uses many polymorphic idioms that Typed Clojure is
poor at checking, so we deemed it too difficult to attempt to
type check. In particular, there are many of usages of the
core functions
\clj{get-in} and \clj{update-in} (functions that deeply lookup
and manipulate maps) which are not even assigned types
in Typed Clojure.
Many function definitions would need to be ignored by the type
checker to work around this.
Furthermore, many manual instantiations
would be needed to check transducers and polymorphic functions
passed to other polymorphic functions.

%\begin{verbatim}
%  - get/get-in
%  - apply + kw args
%  - strong updates
%\end{verbatim}

%\paragraph{Possible errors in programs}


\Dsection{Experiment 3: Specs pass unit tests}
\label{infer:sec:experiment3}

Our final experiment uses our tool to
generate specs (\ref{infer:sec:spec-extension})
instead of types.
Specs are checked at runtime,
so to verify the utility of generated specs,
we enable spec checking while
rerunning the unit tests that were used
in the process of creating them.

At first this might seem like a trivial property, but it serves as
a valuable test of our inference algorithm.
The aggressive merging strategies to minimize aliases and
maximize recognizability, while unsound transformations,
are based on hypotheses about Clojure idioms and how
Clojure programs are constructed.
If, hypothetically, we generated singleton specs for numbers
like we do for keywords and did not eventually upcast
them to \clj{number?}, the specs might be too strict
to pass its unit tests.
Some function specs also perform generative testing based on
the argument and return types provided.
If we collapse a spec too much and include it in such
a spec, it might feed a function invalid input.

Thankfully, we avoid such pitfalls, and so
our generated specs pass their tests for the benchmarks
we tried.
The right of \figref{infer:fig:gentype} shows
our preliminary results. All inferred specs pass the unit
tests when enforced, which tells us they are at least well formed.
Since hundreds of invariants are checked, we can also be more confident
that the specs are useful.


%\Dsubsection{Experiment 3: Generating generative tests}

% We should generate the card playing specs in this guide:
% http://clojure.org/guides/spec

% # How evaluate
% ## qualitative
% Does it make sense??
% 
% 1. Don't run, gen type, manual inspection
%   - done on something small but real
%   - star trek game?
% 
% - Try different eval methods on different programs
%   - try different projects on different methods
%
% 2. Generate types, try type checking programs
%   - record what changes needed to get it to
%     type check 
%   - (on a different program than 1.) 
% 
% 3. Generate spec, insert the spec, run the test
%    with the spec on, also generate tests
%   - does spec ignore the input??
%     or just generate tests
%   - best situation:
%     - spec all passes
%     - then types check with minimal changes
%   - Q: can we use spec's tests to improve
%        types, iteratively?
%        (could throw away exceptions, throw
%         away bad input etc., different options
%         here)
% (optional)
% 4. Generate types, use gradual typing
