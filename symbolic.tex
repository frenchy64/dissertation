\chapter{Background}

As is inevitable for an optional type system, there are many
Clojure programs that Typed Clojure was not designed to type check.
These programs contain Clojure idioms that are often either intentionally
not supported with Typed Clojure's initial design, or 
were introduced to Clojure at a later date.
Regardless, programmers will inevitably want to use these features 
in their Typed Clojure programs---but crucially without breaking
support for existing idioms.
In this part, we explore what kinds of idioms are missing
support in Typed Clojure, and propose solutions in the form of
backwards-compatible extensions.

As we discussed in \partref{part:types}, Typed Clojure's initial
design is strongly influenced by Typed Racket. In particular,
Typed Clojure's static semantics of
combinining local type inference and occurrence typing
to check fully-expanded code
comes directly from Typed Racket.
This shared base is appropriate, given the similarities between
the base Clojure and Racket languages.
It is also effective, seamlessly handling many control flow
idioms, capturing many polymorphic idioms, and often yielding
predictable type error messages.
However, there are important tradeoffs to consider in this design---in the following
sections we introduce them and propose extensions to attempt to nullify
their downsides.

\section{Enhancing local type inference}

Concerning the limitations of local type inference,
Hosoya and Pierce~\cite{hosoya1999good}
isolate two drawbacks.
The first is dealing with ``hard-to-synthesize arguments''.
To understand this, we must appreciate a key ingredient of local type inference
called \emph{bidirectional propagation}, which 
we use the example of type checking \clj{(inc 42)} to demonstrate.
If we have already checked \clj{inc} to have type \clj{[Int -> Int]}, we
now have a choice of how to check the argument \clj{42} is an \clj{Int}.
The first is to ascribe an expected type to \clj{42} of \clj{Int}
and rely on
bidirectional \emph{checking mode} to ensure \clj{42} has the correct type
once we check it.
The second is to infer the type of \clj{42} (without an expected type) using 
bidirectional \emph{synthesis mode}, and then ensure the inferred type
is compatible with \clj{Int} after the fact.
A useful analogy in terms of expressions is that checking mode propagates
information outside-in, and synthesis mode propagates inside-out.
A similar analogy in terms of a type derivation tree (that grows upwards)
relates checking and synthesis modes to information being passed
up and down the tree, respectively.

To best serve the purposes of local type inference, it is crucial to stay in
bidirectional \emph{checking} mode as much as possible.
The ``hard-to-synthesize arguments'' problem occurs when type argument
inference interferes with the ability to stay in checking mode, and
thus forces the bidirectional propagator into synthesis mode
for arguments that require checking mode.
For example, to type check

\clj{(map (fn [x] (inc x)) [1 2 3])},

where \clj{map} has type

\clj{(All [a b] [[a -> b] (Seqable a) -> (Seqable b)])},

we use type argument inference to determine how to instantiate type variables \clj{a}
and \clj{b} based on \clj{map}'s arguments.
Unfortunately, 
to answer this question,
the naive local type inference algorithm~\cite{PierceLTI}
uses synthesis mode to retrieve the argument types,
and so checks \clj{(fn [x] (inc x))} in synthesis mode.
No information is propagated about the type of \clj{x},
so this expression will fail to type check, demonstrating
why functions are hard-to-synthesize.

The second drawback noted by Hosoya and Pierce are
cases where there is no ``best'' type argument to infer.
This occurs when there is not enough information available
to determine how to instantiate a type such that the program
has the best chance of type checking, and so it must be guessed.
A representative case where this occurs is inferring the
type of a reference from just its instantiation, such
that optimal types are given to reads and writes.
For example, the following code creates a Clojure Atom
(a reference type) with initial value \clj{nil}, writes
\clj{0} to the Atom, and then increments the Atom's value.

{
\begin{cljlisting}
(let [r (atom nil)]
  (reset! r 0)
  (inc @r))
\end{cljlisting}
}

What type should \clj{r} be assigned? From its initial binding,
\clj{(Atom nil)} seems appropriate, but the subsequent write
would fail. Alternatively, assigning \clj{(Atom Any)} would
allow the write to succeed, but the the final read would fail
because it expects \clj{Int}.
This demonstrates difficulties of the ``no-best-type-argument'' problem.

Hosoya and Pierce report unsatisfactory results in their attempts to
fix these issues, in both the effectiveness and complexity
in their solutions.
They speculate that these difficulties might be better 
addressed at the language-design level---rather than algorithmically---in ways that
keep the bidirectional propagator in checking mode.
For the ``no-best-type-argument'' problem,
we agree with this assessment, since
addressing the problem mostly amounts to annotating 
all reference constructors.
To this end,
Typed Clojure offers several
wrappers for common functions where this problem
is common---the previous example might use the ``typed''
constructor
\clj{(t/atom :- (U nil Int), nil)}.
However, the ``hard-to-synthesize arguments'' problem
is a deeper and more pervasive issue when checking Clojure code.
We don't have the luxury, desire, nor do we think it would be particularly
successful to introduce new core idioms to Clojure,
and so we attempt to solve the this problem algorithmically.

%\begin{cljlisting}
%(for [i (range 100)]
%  (map (fn [j] (inc j))
%       (range i)))
%\end{cljlisting}

Hosoya and Pierce outline the two main challenges that must be
addressed to solve the ``hard-to-synthesize arguments'' problem.
First, we must provide a strategy for identifying which arguments 
should be avoided.
For instance,
they provide a simple grammar for identifying hard-to-synthesize arguments,
which includes (for Standard ML) unannotated functions and unqualified constructors.
Second, an alternative (probably more complicated) algorithm
for inferring type arguments is needed that also handles
avoided arguments.
Their experiments show that the naive approach does not suffice,
and hint at the delicate handling needed to effectively maximize or minimize
instantiated types to stay in checking mode.
We will now use these challenges as a presentational framework to outline our own approach.

In our experience, the most common hard-to-synthesize expression in Clojure code
is the function.
Clojure's large standard library of higher-order functions and encouragement
of functional programming result in many usages of anonymous functions, which almost
always require annotations to check with Typed Clojure.
So, to answer Hosoya and Pierce's first challenge, 
we avoid checking hard-to-synthesize function expressions by
introducing a new function type: a \emph{symbolic closure type}.
A symbolic closure does not immediately check the function body. Instead,
the function's code along with its local type context is saved
until enough information is available to check
the function body in checking mode.
We present more details about symbolic closures in \chapref{chapter:symbolic:symbolic-closures}.

Now that we have delayed the checking of hard-to-check arguments,
Hosoya and Pierce's second challenge calls for an enhanced
type argument reconstruction algorithm to soundly handle
them.
Our investigation led us to create \emph{directed local type inference}
(\chapref{chapter:symbolic:directed-lti}),
which determines the possible data flows through a polymorphic function
by noting the positions of type variable occurrences, and attempts to
use this information to check its arguments in an optimal order for remaining
in bidirectional checking mode.

\section{Custom typing rules}

Besides local type inference,
another significant feature inherited from Typed Racket is that
code is fully expanded before checking.
This unfortunately means that macros with complex expansions
are often uncheckable, and display cryptic error messages when attempting
to do so.
We investigate providing the user with \emph{custom typing rules} (\chapref{chapter:symbolic:custom-rules})
as an extension point to customize how to type check a macro before
it is expanded.
As discussed in 
\partref{part:implementations}, Typed Clojure's initial design does
not support custom typing rules, so we exploit the infrastructure
discussed there,
and present our investigation into the user interface for the rules in
\chapref{chapter:symbolic:custom-rules}.

% - "Avoiding hard-to-synthesize arguments"
%   1. need mechanism to decide which arguments to avoid
%   2. more complicated scheme for determining best type arguments

% - Problem
%   - many common idioms cannot be checked
%   - limitations of local type inference
%   - made harder by occurrence typing
%   - want general solutions available to all users
%   - preliminary investigation of several techniques
% - Possible solutions
%   - symbolic analysis
%     - symbolic closures
%       - deal with "obvious" local function annotations
%     - inlining
%   - directed local type inference
%     - derive data flow from polymorphic types for more aggressive local type variable inference
%   - custom typing rules
%     - interface for describing how to check an unexpanded macro call
%       - or complex functions
%     - custom errors
% - Constraints
%   - some speculation of how well they compose together
%   - small models without rigorous proofs
%   - case studies with real Clojure idioms

\chapter{Symbolic Closure Types}
\label{chapter:symbolic:symbolic-closures}

In local type inference, functions are hard-to-synthesize types for.
Put another way, to check a function body successfully, types for
its parameters are needed upfront.
For top-level function definitions, this is not a problem in many
optional type systems since top-level annotations would be provided
for each function.
However, for anonymous functions it's a different story.
The original local type inference algorithm~\cite{PierceLTI}
lacks a synthesis rule for unannotated functions, but due to the prevalence
of anonymous functions in languages like JavaScript, Racket, and Clojure,
optional type systems for the languages add their own rules.

Typed Racket and Typed Clojure implement a simple but sound strategy
to check unannotated functions. The body of the function is checked
in a type context where its parameters are of type \clj{Any},
the \texttt{Top} type.
This helps check functions that don't use their arguments, or only
use them in positions that require type \clj{Any}.
For example, both \clj{(fn [x] "a")} and \clj{(fn [x] (str "x: " x))} 
synthesize to \clj{[Any -> String]} in Typed Clojure.
The downsides to this strategy are that unannotated functions are never
inferred as polymorphic, and functions that use their arguments
at types more specific than \clj{Any} are common.

TypeScript~\cite{typescript}, an optional type system for JavaScript,
takes a similar approach, but instead of annotating parameters with
TypeScript's least permissive type called \js{unknown},
by default it assigns parameters the unsound dynamic type \js{any}.
In TypeScript, \js{any} can be implicitly cast to any other type,
so the type checker will (unsoundly) allow any usage of unannotated arguments.
If this behavior is unsatisfactory,
the \js{noImplicitAny} flag removes special handling for unannotated
functions altogether, and TypeScript will demand explicit annotations for all arguments.

In this chapter, we present an alternative approach to checking unannotated functions
based on the insight that a function's body need only be type checked if and when it is called.
For example, the program \clj{(fn [x] (inc x))} cannot throw a runtime error because
the function is never called, and so a type system may soundly treat the function body as unreachable code.
On the other hand, wrapping the same program in the invocation
\clj{((fn [x] (inc x)) nil)}
makes the runtime error possible, and so a sound static type system must flag the error.

Exploiting this insight in the context of a bidirectional type checker using
local type inference requires many considerations.
First, we must decide in which situations is it desirable to delay checking a function.
Second, we must identify the information that must be saved in order to delay checking a function,
and then choose a suitable format for packaging that information.
Third, we must identify how a function is deemed ``reachable'',
and then which component of the type system is responsible for checking a function body.
Fourth, it is desirable to identify and handle the ways in which 
infinite loops are possible, such as the checking of a delayed function triggering
another delayed function to check, which triggers another delayed check, ad nauseam.
Fifth, we must determine how delayed functions interact with polymorphic types
during type argument reconstruction.

\section{Overview}

\section{Formal model}

\section{Comparison to let-polymorphism}

\section{Experiments}

% - Solution
%   - "obvious" function annotations
%     - can be derived from usage context
%   - introduce "symbolic" closure types
%     - a function's type is its code + typed local scope
%   - don't need to check a function that isn't called
% - Constraints
%   - wildcard "?" type
%     - needed to provide argument types while inferring body
%     - from Colored LTI
%   - Infinite loops
%     - subtyping
%     - type generalization
%     - term reduction limits
%   - user-level story
%     - symbolic closures enabled by flag
%     - users cannot write a symbolic closure
%     - that way, global annotations cannot contain a symbolic closure
%       - helps with polymorphism story
%         - constraint solving
%           - hypothesis/goal: only one side of contraint solving can have a symbolic closure
%             - one side is from global annotation, other side from local inference
%     - compatible with occurrence typing
%   - reporting errors
%     - suggesting types
%     - avoid showing inlining to users
%   - checking fn with arguments at type Bot is equivalent (?) to not checking at all
%     - what about strange disjoint ordered intersection types like `into`
%     - do they break? do they need initial Bot arities?
%   - 0-n checks to same function
%     - avoid double expansion
%       - many copies of symbolic closures are made, could be expanded at different times
%         - how to synchronize?
%     - skipping unreachable functions
%       - potential for latent bugs, if type checker turned off in future and fn is made reachable
%     - performance
%   - consistent evaluation results
%     - how to ensure correct inlining?
%     - relationship between inlined and evaluated code?
%       - do we want to "undo" the inlining when finally evaluating?
%   - when to use a closure type?
%     - partial annotations
%   - polymorphism
%     - postpone discussion to next chapter
%   - applying symbolic analysis to infer loop/recur annotations
%     - similar issues
%     - different type generalization story?
%   - comparison to let-polymorphism
%     - expressiveness
%     - performance
%   - help check macros?
%     - not directly applicable, since too much context would be lost
%       - would help check *more* of an expansion, but error messages
%         are still unrelated to original code
%   - is this a sound strategy?
%     - faithfully simulates beta reduction
%     - termination story?
%   - case studies
%     - criteria:
%       - good errors?
%       - predictable behavior?
%       - performance?
%     - simple eta expansions
%       - (+ 1 2)
%       - ((fn [x y] (+ x y)) 1 2)
%     - let-bound functions
%       - (+ 1 2)
%       - (let [plus (fn [x y] (+ x y))]
%           (plus 1 2))
%     - y-combinator
%       - stress test
%     - let-polymorphism worst case (exponential) comparison
%       - stress test
%     - completely inlined transducers
%       - case study: inlining map + comp
%         - why: non recursive polymorphic functions
%           - common idiom
%         - how to report errors?
%   - polymorphic function-intersection types
%     - how to handle, do we need backtracking?
%     - do we need to recheck arguments? 

\chapter{Directed Local Type Inference}
\label{chapter:symbolic:directed-lti}

\section{Colored local type inference}

% - Solution
%   - extend colored LTI with directed inference
%   - introduce constrained types
%   - derive data flow from (variances of) polymorphic variable occurrences 
%   - simple example
%     - (identity 1)
%     - demonstrate how this is checked with colored LTI
%     - compare to directed LTI:
%       - 2/----v
%         [x -> x]  Int
%          ^--------/1
%
%         1. Int flows to contravariant position
%         2. contravariant position flows to covariant position (because it's on the other side of ->)
%       - no loop, because variables not under different numbers of function types
%         - (we don't know the precise rule yet)
%   - complex example
% - Constraints
%   - advantages over colored LTI
%     - aids symbolic analysis
%       - because we derive potential dataflows, we don't need to over-approximate,
%         and thus trigger unneeded symbolic analysis
%         - which might then fail because of not enough contextual information
%   - disadvantages over colored LTI
%     - significant deviation from LTI
%       - constrained types
%       - aggressive local inference based on data flows
%     - not obvious how to prove soundness
%   - infinite loops
%     - how to manage cycles in inferred data flow 
%   - constraint solving
%     - constrained types
%       - literature (see symb.tex)
%   - flow diagrams
%     - see symb.tex
%   - relationship to colored LTI model
%     - see symb.tex
%   - related work
%     - ML_sub
%     - see: symb.tex

\chapter{Custom Typing rules}
\label{chapter:symbolic:custom-rules}

% - Solution
%   - allow users to provide custom typing rules
%   - 
% - Constraints
%   - wildcard type from colored LTI useful
%   - custom error messages
%     - propagation via expected types
%       - outer-most wins
%   - using clojure.spec to conform/unform
%     - to rip apart and put syntax back together
%     - more robust than manual parsing
%   - differences with Turnstile
%     - in Turnstile, the macro *is* the rule
%       - here, we separate the two
%       - we preserve the macro call until evaluation
%       - use the typing rule to expand "under" the macro as many times as we want
%         - can do this 0-n times, thus compatible with directed LTI & symbolic analysis
